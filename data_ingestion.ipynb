{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5dbcaed-3aeb-4d28-85f7-ff9476aec307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf511d-cd98-4fa1-9f1c-fc08f7f3e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data for a given month as dataframe\n",
    "def get_month_data(year: int, month: int, select_cols: str): \n",
    "    #get correct number of days based on month\n",
    "    match month:\n",
    "        case 2: \n",
    "            max_days = 28\n",
    "        case 1 | 3 | 5 | 7 | 8 | 10 | 12:\n",
    "            max_days = 31\n",
    "        case 4 | 6 | 9 | 11:\n",
    "            max_days = 30\n",
    "    #write select statement given columns \n",
    "    statement = f\"\"\"SELECT {select_cols}\n",
    "        FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*`, \n",
    "        UNNEST(hits) as hits LEFT JOIN UNNEST(product) as product LEFT JOIN UNNEST(promotion) AS promotion \n",
    "        WHERE _TABLE_SUFFIX BETWEEN FORMAT_DATE('%Y%m%d', '{year}-{month}-01') AND FORMAT_DATE('%Y%m%d', '{year}-{month}-{max_days}')\n",
    "        AND (eventInfo.eventAction IS NOT NULL OR eCommerceAction.action_type != '0')\n",
    "        ORDER BY date, unique_id, hitNumber ASC;\"\"\" \n",
    "        #initialize bigquery connection\n",
    "    client = bigquery.Client()\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    query_job = client.query(statement, job_config=job_config)\n",
    "    results = query_job.result().to_dataframe()\n",
    "    return(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e02ea58-3ef1-4069-8fbe-8cd05b1be3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten JSON records\n",
    "def flatten(df, *cols):\n",
    "    for col in cols:\n",
    "        temp = pd.json_normalize(df[col])\n",
    "        print(col, len(temp.columns))\n",
    "        df = pd.concat([df, temp], axis = 1)\n",
    "        df = df.drop(col, axis = 1)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c57fada-c1bf-4a40-b622-a678625dc350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that are than 50% null or only have 1 unique value\n",
    "def drop_columns(df):\n",
    "    nulls = [None, '(not set)', '(not provided)', '(none)', '(not available in demo dataset)', 'not available in demo dataset', np.nan, [], '[]', ''] \n",
    "    #remove duplicates\n",
    "    duplicated = df.columns[df.columns.duplicated()]\n",
    "    for col in duplicated:\n",
    "        temp = df[col].iloc[:,0]\n",
    "        #drop both duplicates\n",
    "        df = df.drop(col, axis = 1)\n",
    "        #add back a single columns \n",
    "        df[col] = temp\n",
    "    for col in (df.columns):\n",
    "        print(col)\n",
    "        #remove all nan only columns\n",
    "        if pd.isna(df[col]).all() or df[col].isin(nulls).all():\n",
    "            df = df.drop(col, axis =1)\n",
    "        #remove columns where >50% of values are null: \n",
    "        elif (df[col].isin(nulls).value_counts()[False]/len(df.index) < 0.5):\n",
    "            df = df.drop(col, axis = 1)\n",
    "        #remove all cols that only have 1 unique value \n",
    "        elif (len(df[col].astype(str).unique()) <= 1):\n",
    "            df = df.drop(col, axis =1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91158f8a-1786-4d63-a8fc-80e0df241290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing pipeline\n",
    "def preprocess(year, month, select_cols, *flatten_cols):\n",
    "    month_df = get_month_data(year, month, select_cols)\n",
    "    print(\"queried\")\n",
    "    flatten_df = flatten(month_df, *flatten_cols)\n",
    "    print(\"flattened\")\n",
    "    #replace all empty arrays so they can be compared for null counts\n",
    "    flatten_df = flatten_df.applymap(lambda v: '[]' if isinstance(v, np.ndarray) and len(v) == 0 else v)\n",
    "    dropped_df = drop_columns(flatten_df)\n",
    "    print(\"dropped columns\")\n",
    "    return(dropped_df)\n",
    "def export(df, name):\n",
    "    try:\n",
    "        df.to_csv(f'{name}.csv', mode = 'x', index= False)\n",
    "    except ValueError:\n",
    "        print('file already exists')\n",
    "    print(\"exported to csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c45a74-ad12-4a6a-91c4-447cbd5efd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query to get EDA and training data \n",
    "select_cols = \"\"\"date, CONCAT(fullVisitorId, visitId) AS unique_id, totals, trafficSource, device, geoNetwork, product, promotion, hits, eventInfo.eventAction AS event_action, \n",
    "        CASE\n",
    "        WHEN eventInfo.eventAction = 'Add to Cart' OR eCommerceAction.action_type = '3' THEN 1\n",
    "        ELSE 0\n",
    "        END AS is_addtocart\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cf47b-6a1c-46dc-b3ad-15d9aa4e7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "oct = preprocess(2016, 10, select_cols, 'product', 'promotion', 'hits', 'trafficSource', 'device', 'geoNetwork','totals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a913e32-d2a3-425a-a1e3-8d8a6287beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select statement for validation\n",
    "select_final = \"\"\"date, CONCAT(fullVisitorId, visitId) AS unique_id, product.productListName,\n",
    "product.localProductPrice,\n",
    "eventInfo.eventCategory,\n",
    "type,\n",
    "eCommerceAction.step,\n",
    "product.productPrice,\n",
    "totals.pageviews,\n",
    "page.pagePath,\n",
    "appInfo.screenName,\n",
    "CASE\n",
    "    WHEN eventInfo.eventAction = 'Add to Cart' OR eCommerceAction.action_type = '3' THEN 1\n",
    "    ELSE 0\n",
    "    END AS is_addtocart\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f099278-537e-4f5a-ae4a-4a0ef0173229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering and cleaning of validation data \n",
    "def kfeature_eng(data):\n",
    "    #encoding pagepath\n",
    "    data['path_depth'] = [len(s.split('/'))-1 for s in data['pagePath']]\n",
    "    #renaming\n",
    "    data[['page.pagePath', 'appInfo.screenName', 'eventInfo.eventCategory','eCommerceAction.step']] = data[['pagePath', 'screenName', 'eventCategory','step']]\n",
    "    data = data.drop(['pagePath', 'screenName', 'eventCategory','step'], axis =1)\n",
    "    #impute\n",
    "    data.loc[:, 'localProductPrice'] = data['localProductPrice'].fillna(data['localProductPrice'].median())\n",
    "    data.loc[:,'productPrice'] = data['productPrice'].fillna(data['productPrice'].median())\n",
    "    data.loc[:,'pageviews'] = data['pageviews'].fillna(data['pageviews'].median())\n",
    "    data['eventInfo.eventCategory'] = data['eventInfo.eventCategory'].fillna(data['eventInfo.eventCategory'].mode())\n",
    "    data = data.drop(['date', 'unique_id'], axis = 1)\n",
    "    data = data.fillna(data.mode())\n",
    "    data = data.drop_duplicates()\n",
    "    data = data.reset_index().drop('index', axis =1)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99576792-2e2f-4efc-afe6-f03b0f258279",
   "metadata": {},
   "outputs": [],
   "source": [
    "mar1 = get_month_data(2017, 3, select_final)\n",
    "test_mar = kfeature_eng(mar1)\n",
    "export(mar_test, 'kf_test_317')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57297755-b830-4608-9291-187866767948",
   "metadata": {},
   "outputs": [],
   "source": [
    "feb = get_month_data(2017,2,select_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792bbe3b-3364-441d-aafc-2f082cccec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfeature_eng(feb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb6777-1c4c-48bc-b9a3-ba30c117310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get validation data for whole year of 2017\n",
    "for i in range (1, 13):\n",
    "    month_df = get_month_data(2017, i, select_final)\n",
    "    eng_df = kfeature_eng(month_df)\n",
    "    export(eng_df, f'validation_data/kf_test_{i}17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fce0aa2-3655-4bcd-bfde-a74dbbe0308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported to csv\n",
      "exported to csv\n",
      "exported to csv\n",
      "exported to csv\n",
      "exported to csv\n"
     ]
    }
   ],
   "source": [
    "#get data for demo\n",
    "for i in range (8,13):\n",
    "    month_df = get_month_data(2016, i, select_final)\n",
    "    eng_df = kfeature_eng(month_df)\n",
    "    export(eng_df, f'validation_data/kf_test_{i}16')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360aed25-dfb5-4e4f-b130-5cffbb5e75b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "local-conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
