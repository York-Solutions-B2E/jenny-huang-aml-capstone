{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a524598-7842-439a-ae16-94d0d8ac6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training \n",
    "import os\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be457964-2b40-4334-8031-84e34f64ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"york-bb-cohort\"  \n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5b2860-10be-4450-8c78-cf67b59d58d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad3262d-5a66-4ffa-808a-89cd999c51b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://huang-capstone-york-bb-cohort-unique/...\n"
     ]
    }
   ],
   "source": [
    "BUCKET_URI = f\"gs://huang-capstone-{PROJECT_ID}-unique\" \n",
    "# ! gsutil mb -l $REGION $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212aab66-082c-4723-839b-495cf6dbe504",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63fa57-eedd-454e-a6d2-d2068a659173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hello. something happened to my code here and it is all gone. I had created and trained the model using a TabularDataset pulled from a GCS CSV exported from the eda file. \n",
    "#I created the model using a AutoMLTabularTrainingJob set to classification with the given dataset and mapped column transformations\n",
    "#But you can do everything from the Cloud Console too.\n",
    "#Create a new tabular dataset using the query described in data_ingestion.ipynb\n",
    "#Run a tabular training job set to classification with the relevant dataset and the target set to "is_addtocart" and the relevant numeric and categorical column transformations\n"
    ",
    "dataset = aiplatform.TabularDataset.create(\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "local-conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
